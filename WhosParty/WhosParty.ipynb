{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFace will run on CPU\n",
      "Directory  /Users/sidpremkumar /.deepface created\n",
      "Directory  /Users/sidpremkumar /.deepface/weights created\n"
     ]
    }
   ],
   "source": [
    "from igramscraper.instagram import Instagram\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "\n",
    "import detect_gender \n",
    "\n",
    "import tempfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cookie': 'csrftoken=3087q0EAfTMKtMjkktuQawJZ3FsIwEcr; ds_user_id=1415761657; ig_did=21C1AD2F-3DEB-40DA-8341-FF199AE7D5ED; rur=FTW; sessionid=1415761657%3AxeayPXzOPfcTFw%3A23; shbid=11014; shbts=1587669162.142111; mid=XqHoqAAEAAGI9QcNPET-wjbzBsmj; ',\n",
       " 'referer': 'https://www.instagram.com/',\n",
       " 'x-csrftoken': '3087q0EAfTMKtMjkktuQawJZ3FsIwEcr',\n",
       " 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instagram = Instagram()\n",
    "instagram.with_credentials('therealsidpremkumar', 'Sidhartha98', '/Users/sidpremkumar/Documents/Projects/WhosParty/WhosParty')\n",
    "instagram.login(force=False,two_step_verificator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://instagram.fnyc1-1.fna.fbcdn.net/v/t51.2885-19/s150x150/16123627_1826526524262048_8535256149333639168_n.jpg?_nc_ht=instagram.fnyc1-1.fna.fbcdn.net&_nc_ohc=5lWz02wGLEwAX8C_wo8&oh=2afb5ca220bbb601f7e4dccf5e54f88c&oe=5EC9F858\n",
      "Male     0.986141\n",
      "Asian    0.022277\n",
      "White    0.221160\n",
      "Black    0.081946\n",
      "Name: 0, dtype: float64\n",
      "{'Male': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidpremkumar/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/sidpremkumar/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "account = instagram.get_account(\"barackobama\")\n",
    "# print(account.profile_pic_url)\n",
    "\n",
    "# Create temp file and download profile picture\n",
    "tmpfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "urllib.request.urlretrieve(str(account.profile_pic_url_hd), tmpfile.name)\n",
    "\n",
    "\n",
    "print(account.profile_pic_url_hd)\n",
    "\n",
    "\n",
    "model_path = 'face_model.pkl'\n",
    "with open(model_path, 'rb') as f:\n",
    "        clf, labels = pickle.load(f, encoding='latin1')\n",
    "        \n",
    "\n",
    "pred, locs = detect_gender.predict_one_image(tmpfile.name, clf, labels)\n",
    "\n",
    "final_analysis = {}\n",
    "\n",
    "def analyze_pred(pred):\n",
    "    \"\"\"\n",
    "    Helper function to analyze the pred array returned from predict_one_image\n",
    "    :param pandas.Dataframe pred: Results of pred\n",
    "    Returns dict with predictions\n",
    "    \"\"\"\n",
    "    # Our pred array is structured as follows: [Male, Asian, White, Black]\n",
    "    ret = {}\n",
    "    for index, face in pred.iterrows():\n",
    "        if face[\"Male\"] >= 0.5:\n",
    "            ret[\"Male\"] = 1\n",
    "        race = np.argmax(face[1:4])\n",
    "        print(face)\n",
    "        if face[race] >= 0.5:\n",
    "            ret[pred.columns[race]] = 1\n",
    "    return ret\n",
    "\n",
    "\n",
    "analyized = analyze_pred(pred)\n",
    "\n",
    "for key, value in analyized.items():\n",
    "    if key in final_analysis:\n",
    "        final_anlysis[key] += 1\n",
    "    else:\n",
    "        final_analysis[key] = value\n",
    "\n",
    "print(final_analysis)\n",
    "# Close the temp file\n",
    "tmpfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['emotion', 'age', 'gender', 'race']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Face could not be detected in ', array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       ...,\n\n       [[245, 237, 238],\n        [247, 239, 240],\n        [245, 240, 239],\n        ...,\n        [ 87,  66,  64],\n        [ 87,  66,  64],\n        [ 86,  65,  63]],\n\n       [[245, 237, 238],\n        [246, 238, 239],\n        [243, 238, 237],\n        ...,\n        [ 82,  63,  60],\n        [ 79,  60,  57],\n        [ 77,  58,  55]],\n\n       [[247, 239, 240],\n        [246, 238, 239],\n        [239, 234, 233],\n        ...,\n        [ 66,  47,  44],\n        [ 62,  43,  40],\n        [ 58,  39,  36]]], dtype=uint8), '. Please confirm that the picture is a face photo.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-39c96aff11aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(account.profile_pic_url_hd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdemography\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/test_picture2.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# tmpfile.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/deepface/DeepFace.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(img_path, actions, models)\u001b[0m\n\u001b[1;32m    218\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'emotion'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                 \u001b[0memotion_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'disgust'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'happy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surprise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                                 \u001b[0memotion_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotion_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/deepface/commons/functions.py\u001b[0m in \u001b[0;36mdetectFace\u001b[0;34m(img, target_size, grayscale)\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mimg_pixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Face could not be detected in \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\". Please confirm that the picture is a face photo.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mallocateMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Face could not be detected in ', array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       ...,\n\n       [[245, 237, 238],\n        [247, 239, 240],\n        [245, 240, 239],\n        ...,\n        [ 87,  66,  64],\n        [ 87,  66,  64],\n        [ 86,  65,  63]],\n\n       [[245, 237, 238],\n        [246, 238, 239],\n        [243, 238, 237],\n        ...,\n        [ 82,  63,  60],\n        [ 79,  60,  57],\n        [ 77,  58,  55]],\n\n       [[247, 239, 240],\n        [246, 238, 239],\n        [239, 234, 233],\n        ...,\n        [ 66,  47,  44],\n        [ 62,  43,  40],\n        [ 58,  39,  36]]], dtype=uint8), '. Please confirm that the picture is a face photo.')"
     ]
    }
   ],
   "source": [
    "account = instagram.get_account(\"barackobama\")\n",
    "# print(account.profile_pic_url)\n",
    "\n",
    "# # Create temp file and download profile picture\n",
    "# tmpfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "# urllib.request.urlretrieve(\"https://yt3.ggpht.com/a/AATXAJzmB2-IeNrtY1sTDLuswSK3rH04VFz5Kf0ReA=s900-c-k-c0xffffffff-no-rj-mo\", tmpfile.name)\n",
    "\n",
    "\n",
    "# print(account.profile_pic_url_hd)\n",
    "\n",
    "demography = DeepFace.analyze(\"test/test_picture2.jpg\")\n",
    "\n",
    "# tmpfile.close()\n",
    "\n",
    "print(demography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidpremkumar/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/sidpremkumar/Documents/Projects/WhosParty/venv/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "100%|██████████| 1000/1000 [02:05<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Female': 266, 'Male': 187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Female': 266, 'Male': 187}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_pred(pred):\n",
    "    \"\"\"\n",
    "    Helper function to analyze the pred array returned from predict_one_image\n",
    "    :param pandas.Dataframe pred: Results of pred\n",
    "    Returns dict with predictions\n",
    "    \"\"\"\n",
    "    # Our pred array is structured as follows: [Male, Asian, White, Black]\n",
    "    ret = {}\n",
    "    for index, face in pred.iterrows():\n",
    "        if face[\"Male\"] >= 0.5:\n",
    "            ret[\"Male\"] = 1\n",
    "        else:\n",
    "            ret[\"Female\"] = 1\n",
    "        race = np.argmax(face[1:4])\n",
    "        if face[race] >= 0.5:\n",
    "            ret[pred.columns[race]] = 1\n",
    "    return ret\n",
    "\n",
    "\n",
    "def scrape_account(account):\n",
    "    \"\"\"\n",
    "    Scrapes Instagram account\n",
    "    :param igramscraper.model.account.Account account: Instagram account to scrape\n",
    "    \"\"\"\n",
    "    # Create temp file and download profile picture\n",
    "    tmpfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(str(account.profile_pic_url), tmpfile.name)\n",
    "    \n",
    "    # Classify the image\n",
    "    try:\n",
    "        pred, locs = detect_gender.predict_one_image(tmpfile.name, clf, labels)\n",
    "        \n",
    "        analyized = analyze_pred(pred)\n",
    "\n",
    "        # Close the temp file\n",
    "        tmpfile.close()\n",
    "\n",
    "        return analyized\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "    \n",
    "def loop_account(username):\n",
    "    \"\"\"\n",
    "    Loops over a usernames followers\n",
    "    :param String username: Instagram username\n",
    "    Returns dict with relevent classification info\n",
    "    \"\"\"\n",
    "    # Load up our model\n",
    "    model_path = 'face_model.pkl'\n",
    "    with open(model_path, 'rb') as f:\n",
    "            clf, labels = pickle.load(f, encoding='latin1')\n",
    "        \n",
    "    account = instagram.get_account(username)\n",
    "    followers = instagram.get_followers(account.identifier, 1000, 100, delayed=True)\n",
    "    final_analysis = {}\n",
    "    for i in tqdm(range(len(followers['accounts']))):\n",
    "        follower = followers['accounts'][i]\n",
    "        if follower.profile_pic_url:\n",
    "            analyzed = scrape_account(follower)\n",
    "            for key, value in analyzed.items():\n",
    "                if key in final_analysis:\n",
    "                    final_analysis[key] += 1\n",
    "                else:\n",
    "                    final_analysis[key] = value\n",
    "    print(final_analysis)\n",
    "    return final_analysis\n",
    "\n",
    "loop_account('barstoolsports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
